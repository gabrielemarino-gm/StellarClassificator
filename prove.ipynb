{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression, SelectKBest\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfStars = pd.read_csv('Skyserver_12_15_2020 3 45 07 AM.csv', na_values=\"?\")\n",
    "dfStars = pd.read_csv('FileCSV/star_classification.csv', na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the classed-class with numerical data\n",
    "dfStars['class'] = dfStars['class'].replace({'GALAXY': 0, 'STAR': 1, 'QSO': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test\n",
    "X = dfStars.drop('class', axis=1)\n",
    "y = dfStars['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['objid', 'ra', 'run','rerun','camcol','field','fiberid'], axis = 1, inplace=True) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for EPS = 0.1 e MIN_SAMPLES = 2:  -0.6382729104157495\n",
      "Silhouette score for EPS = 0.1 e MIN_SAMPLES = 4:  -0.6851897386920022\n",
      "Silhouette score for EPS = 0.1 e MIN_SAMPLES = 8:  -0.569159589777764\n",
      "Silhouette score for EPS = 0.1 e MIN_SAMPLES = 10:  -0.4949190923878875\n",
      "Silhouette score for EPS = 0.5 e MIN_SAMPLES = 2:  -0.5459116711181403\n",
      "Silhouette score for EPS = 0.5 e MIN_SAMPLES = 4:  -0.38431007899298303\n",
      "Silhouette score for EPS = 0.5 e MIN_SAMPLES = 8:  -0.25374005594808696\n",
      "Silhouette score for EPS = 0.5 e MIN_SAMPLES = 10:  -0.2927925892207605\n",
      "Silhouette score for EPS = 1 e MIN_SAMPLES = 2:  -0.11432325995002039\n",
      "Silhouette score for EPS = 1 e MIN_SAMPLES = 4:  0.18087522784821394\n",
      "Silhouette score for EPS = 1 e MIN_SAMPLES = 8:  0.4141007483057308\n",
      "Silhouette score for EPS = 1 e MIN_SAMPLES = 10:  0.4204837299300606\n"
     ]
    }
   ],
   "source": [
    "#DBSCAN\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Selezionare le colonne di interesse\n",
    "cols = ['u', 'g', 'r', 'i', 'z', 'specobjid', 'redshift']\n",
    "df_merged = pd.concat([X_train, y_train], axis=1) # type: ignore\n",
    "data = df_merged[cols]\n",
    "\n",
    "# Normalizzare i dati\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(data, columns=['u', 'g', 'r', 'i', 'z', 'specobjid', 'redshift'])\n",
    "\n",
    "# Definire i parametri di ingresso\n",
    "eps_list = [0.1, 0.5, 1]\n",
    "min_samples_list = [2, 4, 8, 10]\n",
    "\n",
    "for eps_i in eps_list:\n",
    "    for min_samples_i in min_samples_list:\n",
    "\n",
    "        # Eseguire DBSCAN\n",
    "        dbscan = DBSCAN(eps=eps_i, min_samples=min_samples_i)\n",
    "        dbscan.fit(data)\n",
    "\n",
    "        # Identificare gli outlier\n",
    "        outliers = data[dbscan.labels_ == -1]\n",
    "\n",
    "        # Calcolare la silhouette score\n",
    "        score = silhouette_score(data, dbscan.labels_)\n",
    "\n",
    "        # Stampa del risultato\n",
    "        print(f\"Silhouette score for EPS = {eps_i} e MIN_SAMPLES = {min_samples_i}: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for EPS = 4 e MIN_SAMPLES = 5000:  0.62214534699581\n"
     ]
    }
   ],
   "source": [
    "# Definire i parametri di ingresso\n",
    "eps_list = 4\n",
    "min_samples_list = 5000\n",
    "\n",
    "\n",
    "# Eseguire DBSCAN\n",
    "dbscan = DBSCAN(eps=eps_list, min_samples=min_samples_list)\n",
    "dbscan.fit(data)\n",
    "\n",
    "# Identificare gli outlier\n",
    "outliers = data[dbscan.labels_ == -1]\n",
    "\n",
    "# Calcolare la silhouette score\n",
    "score = silhouette_score(data, dbscan.labels_)\n",
    "\n",
    "# Stampa del risultato\n",
    "print(f\"Silhouette score for EPS = {eps_list} e MIN_SAMPLES = {min_samples_list}: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u: (1, 18)\n",
      "g: (1, 18)\n",
      "z: (1, 18)\n"
     ]
    }
   ],
   "source": [
    "df_filtered = dfStars[dfStars['u'] < 0]\n",
    "print(\"u: \" + str(df_filtered.shape))\n",
    "\n",
    "df_filtered = dfStars[dfStars['g'] < 0]\n",
    "print(\"g: \" + str(df_filtered.shape))\n",
    "\n",
    "df_filtered = dfStars[dfStars['z'] < 0]\n",
    "print(\"z: \" + str(df_filtered.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Definizione del modello LOF\n",
    "lof = LocalOutlierFactor()\n",
    "\n",
    "# Definizione del range di valori per i parametri\n",
    "param_grid = {'n_neighbors': [1, 5, 10, 20, 30], 'contamination': [0.001, 0.01, 0.1, 'auto']}\n",
    "\n",
    "# Creazione della griglia di parametri\n",
    "grid_lof = GridSearchCV(lof, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit del modello sui dati e ricerca dei migliori parametri\n",
    "grid_lof.fit(X)\n",
    "\n",
    "# Stampa dei migliori parametri\n",
    "print(\"I migliori parametri sono: \", grid_lof.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 11)\n",
      "(69300, 11)\n"
     ]
    }
   ],
   "source": [
    "#OUTLIER \n",
    "\n",
    "df_merged = pd.concat([X_train, y_train], axis=1) # type: ignore\n",
    "print(df_merged.shape)\n",
    "\n",
    "# Creates the LocalOutlierFactor object with n_neighbors and contamination parameters\n",
    "lof = LocalOutlierFactor(n_neighbors=1, contamination=0.01) # type: ignore\n",
    "\n",
    "# Select the DataFrame for the GALAXY class \n",
    "# Extract the features from the DataFrame\n",
    "# Get the outliers with the fit_predict method\n",
    "XX = df_merged[['u', 'g', 'r', 'i', 'z', 'specobjid', 'redshift']]\n",
    "outliers = lof.fit_predict(XX)\n",
    "df_after_outlier = df_merged[outliers == 1]\n",
    "\n",
    "print(df_after_outlier.shape)\n",
    "\n",
    "X_train = df_after_outlier.drop('class', axis=1)\n",
    "y_train = df_after_outlier['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123768, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    41256\n",
       "1    41256\n",
       "2    41256\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REBALANCING\n",
    "# using oversampling with SMOTE to deal with imbalanced data\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_after_balancing, y_train_after_balancing = sm.fit_resample(X_train, y_train) # type: ignore\n",
    "\n",
    "print(X_train_after_balancing.shape) # type: ignore\n",
    "y_train_after_balancing.value_counts() # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and classs\n",
    "X_train_class = X_train_after_balancing\n",
    "y_train_class = y_train_after_balancing\n",
    "\n",
    "X_test_drop = X_test.drop(['objid', 'ra', 'run', 'rerun', 'camcol', 'field', 'fiberid'], axis = 1) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalizzare i dati\n",
    "scaler = StandardScaler()\n",
    "X_train_class_npArr = scaler.fit_transform(X_train_class)\n",
    "\n",
    "X_train_class_norm = pd.DataFrame(X_train_class_npArr, columns=['dec', 'u', 'g', 'r', 'i', 'z', 'specobjid', 'redshift', 'plate', 'mjd'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "108577842efddff3bd4824ec9bdd12effc6dfe96f030cd77b02bee11f8da132d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
