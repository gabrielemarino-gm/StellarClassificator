{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocessing</h1>\n",
    "The Dataset are made in this way:\n",
    "<ul>\n",
    "    <li>objid       = Object Identifier, the unique value that identifies the object in the image catalog used by the CAS</li>\n",
    "    <li>ra          = Right Ascension angle (at J2000 epoch)</li>\n",
    "    <li>dec         = Declination angle (at J2000 epoch)</li>\n",
    "    <li>u           = Ultraviolet filter in the photometric system</li>\n",
    "    <li>g           = Green filter in the photometric system</li>\n",
    "    <li>r           = Red filter in the photometric system</li>\n",
    "    <li>i           = Near Infrared filter in the photometric system</li>\n",
    "    <li>z           = Infrared filter in the photometric system</li>\n",
    "    <li>run         = Run Number used to identify the specific scan</li>\n",
    "    <li>rereun      = Rerun Number to specify how the image was processed</li>\n",
    "    <li>camcol      = Camera column to identify the scanline within the run</li>\n",
    "    <li>field       = Field number to identify each field</li>\n",
    "    <li>specobjid   = Unique ID used for optical spectroscopic objects (this means that 2 different observations with the same spec_obj_ID must share the output class)</li>\n",
    "    <li>redshift    = redshift value based on the increase in wavelength</li>\n",
    "    <li>plate       = plate ID, identifies each plate in SDSS</li>\n",
    "    <li>mjd         = Modified Julian Date, used to indicate when a given piece of SDSS data was taken</li>\n",
    "    <li>fiberid     = fiber ID that identifies the fiber that pointed the light at the focal plane in each observation</li>\n",
    "    <li>class       = object class (galaxy, star or quasar object)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression, SelectKBest\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start loading the dataset in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objid</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>run</th>\n",
       "      <th>rerun</th>\n",
       "      <th>camcol</th>\n",
       "      <th>field</th>\n",
       "      <th>specobjid</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>mjd</th>\n",
       "      <th>fiberid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>135.689107</td>\n",
       "      <td>32.494632</td>\n",
       "      <td>23.87882</td>\n",
       "      <td>22.27530</td>\n",
       "      <td>20.39501</td>\n",
       "      <td>19.16573</td>\n",
       "      <td>18.79371</td>\n",
       "      <td>3606</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>6.543777e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.634794</td>\n",
       "      <td>5812</td>\n",
       "      <td>56354</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.237665e+18</td>\n",
       "      <td>144.826101</td>\n",
       "      <td>31.274185</td>\n",
       "      <td>24.77759</td>\n",
       "      <td>22.83188</td>\n",
       "      <td>22.58444</td>\n",
       "      <td>21.16812</td>\n",
       "      <td>21.61427</td>\n",
       "      <td>4518</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>1.176014e+19</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.779136</td>\n",
       "      <td>10445</td>\n",
       "      <td>58158</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>142.188790</td>\n",
       "      <td>35.582444</td>\n",
       "      <td>25.26307</td>\n",
       "      <td>22.66389</td>\n",
       "      <td>20.60976</td>\n",
       "      <td>19.34857</td>\n",
       "      <td>18.94827</td>\n",
       "      <td>3606</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>5.152200e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.644195</td>\n",
       "      <td>4576</td>\n",
       "      <td>55592</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.237663e+18</td>\n",
       "      <td>338.741038</td>\n",
       "      <td>-0.402828</td>\n",
       "      <td>22.13682</td>\n",
       "      <td>23.77656</td>\n",
       "      <td>21.61162</td>\n",
       "      <td>20.50454</td>\n",
       "      <td>19.25010</td>\n",
       "      <td>4192</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>214</td>\n",
       "      <td>1.030107e+19</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.932346</td>\n",
       "      <td>9149</td>\n",
       "      <td>58039</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.237680e+18</td>\n",
       "      <td>345.282593</td>\n",
       "      <td>21.183866</td>\n",
       "      <td>19.43718</td>\n",
       "      <td>17.58028</td>\n",
       "      <td>16.49747</td>\n",
       "      <td>15.97711</td>\n",
       "      <td>15.54461</td>\n",
       "      <td>8102</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>137</td>\n",
       "      <td>6.891865e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.116123</td>\n",
       "      <td>6121</td>\n",
       "      <td>56187</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1.237679e+18</td>\n",
       "      <td>39.620709</td>\n",
       "      <td>-2.594074</td>\n",
       "      <td>22.16759</td>\n",
       "      <td>22.97586</td>\n",
       "      <td>21.90404</td>\n",
       "      <td>21.30548</td>\n",
       "      <td>20.73569</td>\n",
       "      <td>7778</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>581</td>\n",
       "      <td>1.055431e+19</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9374</td>\n",
       "      <td>57749</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>1.237679e+18</td>\n",
       "      <td>29.493819</td>\n",
       "      <td>19.798874</td>\n",
       "      <td>22.69118</td>\n",
       "      <td>22.38628</td>\n",
       "      <td>20.45003</td>\n",
       "      <td>19.75759</td>\n",
       "      <td>19.41526</td>\n",
       "      <td>7917</td>\n",
       "      <td>301</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>8.586351e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.404895</td>\n",
       "      <td>7626</td>\n",
       "      <td>56934</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1.237668e+18</td>\n",
       "      <td>224.587407</td>\n",
       "      <td>15.700707</td>\n",
       "      <td>21.16916</td>\n",
       "      <td>19.26997</td>\n",
       "      <td>18.20428</td>\n",
       "      <td>17.69034</td>\n",
       "      <td>17.35221</td>\n",
       "      <td>5314</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>308</td>\n",
       "      <td>3.112008e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.143366</td>\n",
       "      <td>2764</td>\n",
       "      <td>54535</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>212.268621</td>\n",
       "      <td>46.660365</td>\n",
       "      <td>25.35039</td>\n",
       "      <td>21.63757</td>\n",
       "      <td>19.91386</td>\n",
       "      <td>19.07254</td>\n",
       "      <td>18.62482</td>\n",
       "      <td>3650</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>131</td>\n",
       "      <td>7.601080e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.455040</td>\n",
       "      <td>6751</td>\n",
       "      <td>56368</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>196.896053</td>\n",
       "      <td>49.464643</td>\n",
       "      <td>22.62171</td>\n",
       "      <td>21.79745</td>\n",
       "      <td>20.60115</td>\n",
       "      <td>20.00959</td>\n",
       "      <td>19.28075</td>\n",
       "      <td>3650</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>8.343152e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.542944</td>\n",
       "      <td>7410</td>\n",
       "      <td>57104</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              objid          ra        dec         u         g         r  \\\n",
       "0      1.237661e+18  135.689107  32.494632  23.87882  22.27530  20.39501   \n",
       "1      1.237665e+18  144.826101  31.274185  24.77759  22.83188  22.58444   \n",
       "2      1.237661e+18  142.188790  35.582444  25.26307  22.66389  20.60976   \n",
       "3      1.237663e+18  338.741038  -0.402828  22.13682  23.77656  21.61162   \n",
       "4      1.237680e+18  345.282593  21.183866  19.43718  17.58028  16.49747   \n",
       "...             ...         ...        ...       ...       ...       ...   \n",
       "99995  1.237679e+18   39.620709  -2.594074  22.16759  22.97586  21.90404   \n",
       "99996  1.237679e+18   29.493819  19.798874  22.69118  22.38628  20.45003   \n",
       "99997  1.237668e+18  224.587407  15.700707  21.16916  19.26997  18.20428   \n",
       "99998  1.237661e+18  212.268621  46.660365  25.35039  21.63757  19.91386   \n",
       "99999  1.237661e+18  196.896053  49.464643  22.62171  21.79745  20.60115   \n",
       "\n",
       "              i         z   run  rerun  camcol  field     specobjid   class  \\\n",
       "0      19.16573  18.79371  3606    301       2     79  6.543777e+18  GALAXY   \n",
       "1      21.16812  21.61427  4518    301       5    119  1.176014e+19  GALAXY   \n",
       "2      19.34857  18.94827  3606    301       2    120  5.152200e+18  GALAXY   \n",
       "3      20.50454  19.25010  4192    301       3    214  1.030107e+19  GALAXY   \n",
       "4      15.97711  15.54461  8102    301       3    137  6.891865e+18  GALAXY   \n",
       "...         ...       ...   ...    ...     ...    ...           ...     ...   \n",
       "99995  21.30548  20.73569  7778    301       2    581  1.055431e+19  GALAXY   \n",
       "99996  19.75759  19.41526  7917    301       1    289  8.586351e+18  GALAXY   \n",
       "99997  17.69034  17.35221  5314    301       4    308  3.112008e+18  GALAXY   \n",
       "99998  19.07254  18.62482  3650    301       4    131  7.601080e+18  GALAXY   \n",
       "99999  20.00959  19.28075  3650    301       4     60  8.343152e+18  GALAXY   \n",
       "\n",
       "       redshift  plate    mjd  fiberid  \n",
       "0      0.634794   5812  56354      171  \n",
       "1      0.779136  10445  58158      427  \n",
       "2      0.644195   4576  55592      299  \n",
       "3      0.932346   9149  58039      775  \n",
       "4      0.116123   6121  56187      842  \n",
       "...         ...    ...    ...      ...  \n",
       "99995  0.000000   9374  57749      438  \n",
       "99996  0.404895   7626  56934      866  \n",
       "99997  0.143366   2764  54535       74  \n",
       "99998  0.455040   6751  56368      470  \n",
       "99999  0.542944   7410  57104      851  \n",
       "\n",
       "[100000 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dfStars = pd.read_csv('Skyserver_12_15_2020 3 45 07 AM.csv', na_values=\"?\")\n",
    "dfStars = pd.read_csv('FileCSV/star_classification.csv', na_values=\"?\")\n",
    "dfStars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStars.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I check the distribution of the Labeled-Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStars['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1, 1, figsize=(5,5), sharey=True)\n",
    "sns.countplot(x='class',data = dfStars, ax = axes, order = dfStars['class'].value_counts().index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check same info about the feature of the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Nan or Null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStars.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if there is some duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStars[dfStars.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Normalization of the classed-class</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the classed-class with numerical data\n",
    "dfStarsNormalize = dfStars\n",
    "dfStarsNormalize['class'] = dfStarsNormalize['class'].replace({'GALAXY': 0, 'STAR': 1, 'QSO': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Split the dataset in training set and test set.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 17), (100000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into features and classs\n",
    "X = dfStarsNormalize.drop('class', axis=1)\n",
    "y = dfStarsNormalize['class']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train and test set\n",
      "(70000, 17)\n",
      "(30000, 17)\n",
      "\n",
      "Distribution of the labeled-classes\n",
      "\n",
      "Training Set\n",
      "0    41636\n",
      "1    15044\n",
      "2    13320\n",
      "Name: class, dtype: int64\n",
      "\n",
      "Test Set\n",
      "0    17809\n",
      "1     6550\n",
      "2     5641\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "print('Shape of the train and test set')\n",
    "print(X_train.shape) # type: ignore\n",
    "print(X_test.shape) # type: ignore\n",
    "print()\n",
    "print('Distribution of the labeled-classes')  \n",
    "print()\n",
    "print(\"Training Set\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Feature Selection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['objid','run','rerun','camcol','field','fiberid'], axis = 1, inplace=True) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>USING: mutual_info_regression</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola il coefficiente di informazione mutua per ogni feature\n",
    "mi = mutual_info_regression(X_train, y_train)\n",
    "mi.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>USING: f_regretion</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eseguiamo il test di ANOVA utilizzando f_regression\n",
    "scores, pvalues = f_regression(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following DataFrame shows the score achieved by each attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfScores = pd.DataFrame()\n",
    "dfScores['ra'] = [scores[0], mi[0]]\n",
    "dfScores['dec'] = [scores[1], mi[1]]\n",
    "dfScores['u'] = [scores[2], mi[2]]\n",
    "dfScores['g'] = [scores[3], mi[3]]\n",
    "dfScores['r'] = [scores[4], mi[4]]\n",
    "dfScores['i'] = [scores[5], mi[5]]\n",
    "dfScores['z'] = [scores[6], mi[6]]\n",
    "dfScores['specobjid'] = [scores[7], mi[7]]\n",
    "dfScores['redshift'] = [scores[8], mi[8]]\n",
    "dfScores['plate'] = [scores[9], mi[9]]\n",
    "dfScores['mjd'] = [scores[10], mi[10]]\n",
    "dfScores.index = ['f_regretion', 'mutual_info_regretion'] # type: ignore\n",
    "dfScores.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un oggetto SelectKBest con il valore di k desiderato (ad esempio 10)\n",
    "selector = SelectKBest(score_func=f_regression, k=10)\n",
    "\n",
    "# Adatta il selector al dataset e seleziona le feature\n",
    "X_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# Stampa le feature selezionate\n",
    "print(\"Feature selezionate:\")\n",
    "print(X_train.columns[selector.get_support()]) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Delete Features</h3>\n",
    "Now we need to drop the useless features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.keys() # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all the feautre with score < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['ra', 'dec', 'u'], axis = 1, inplace=True) # type: ignore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Rebalance Dataset</h1>\n",
    "I decide to use the method resample() for rebalance my DataSet.<br>\n",
    "I add features into the two minority classes (STAR, QSO) until they reach the class with the higer number of examble (GALAXY). <br>\n",
    "In the following snip of code I implement an over sampling using SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124908, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    41636\n",
       "1    41636\n",
       "2    41636\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using oversampling with SMOTE to deal with imbalanced data\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_after_balancing, y_train_after_balancing = sm.fit_resample(X_train, y_train) # type: ignore\n",
    "\n",
    "print(X_train_after_balancing.shape) # type: ignore\n",
    "y_train_after_balancing.value_counts() # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import resample\n",
    "# \n",
    "# # I need to use a Dataframe with the labeled-class\n",
    "# df_balanced = X_train\n",
    "# df_balanced['class'] = y_train # type: ignore\n",
    "# \n",
    "# # Split the dataset in 3 part, one for each class\n",
    "# df_class_0 = df_balanced[df_balanced[\"class\"] == 0] # type: ignore\n",
    "# df_class_1 = df_balanced[df_balanced[\"class\"] == 1] # type: ignore\n",
    "# df_class_2 = df_balanced[df_balanced[\"class\"] == 2] # type: ignore\n",
    "# \n",
    "# # Find the majority class\n",
    "# min_class = df_balanced[\"class\"].value_counts().idxmin() # type: ignore\n",
    "# \n",
    "# # We oversample the least numerous classes\n",
    "# df_class_1_over = resample(df_class_1,\n",
    "#                             replace=True, # Sample with replacement\n",
    "#                             n_samples=len(df_class_0), # Match number in majority class\n",
    "#                             random_state=42) # reproducible results\n",
    "# df_class_2_over = resample(df_class_2,\n",
    "#                             replace=True, # Sample with replacement\n",
    "#                             n_samples=len(df_class_0), # Match number in majority class\n",
    "#                             random_state=42) # reproducible results\n",
    "# \n",
    "# # Join the tre dataframe\n",
    "# df_balanced = pd.concat([df_class_0, df_class_1_over, df_class_2_over]) # type: ignore\n",
    "# \n",
    "# # Mix the data\n",
    "# df_balanced = df_balanced.sample(frac=1, random_state=42)\n",
    "#\n",
    "# df_balanced['class'].value_counts() # type: ignore\n",
    "# print(df_balanced.shape) # type: ignore\n",
    "# We need to split again the labeled-class from the other attribute inside the  ***df_balanced***\n",
    "# X_train_after_balancing = df_balanced.drop('class', axis=1) # type: ignore\n",
    "# y_train_after_balancing = df_balanced['class'] # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-weight: bold\">CLASSIFICATION</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>KNeighborsClassifier</h2>\n",
    "I tried to perform KNN with different k, for understand which is the best. <br>\n",
    "I decided to use the euclidean and the manhattan distance, for make a comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_drop = X_test.drop(['ra', 'dec', 'u', 'objid','run','rerun','camcol','field','fiberid'], axis = 1) # type: ignore\n",
    "\n",
    "k_neighbors = 100\n",
    "metrics = ['euclidean', 'manhattan']\n",
    "\n",
    "accuracy_total = []\n",
    "for k in range(1, k_neighbors+1, 1):\n",
    "    accuracy_k = []\n",
    "    for metric in metrics:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "        knn.fit(X_train_after_balancing, y_train_after_balancing)\n",
    "        y_predKNN = knn.predict(X_test_drop)\n",
    "        accuracy = accuracy_score(y_test, y_predKNN)\n",
    "        accuracy_k.append(accuracy)\n",
    "        # print(f\"For metric = {metric} and k = {k}:      ACCURACY = {accuracy}\")\n",
    "    accuracy_total.append(accuracy_k)\n",
    "\n",
    "accuracy_df = pd.DataFrame(np.array(accuracy_total), columns=metrics)\n",
    "k_df = pd.DataFrame([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100], columns=['k'])\n",
    "accuracy_join= k_df.join(accuracy_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snip of code shows us the trend of the KNN's accuracy for the euclidean and manhattan distance.<br> \n",
    "The graph for each distance it's almost the same. But the accurasy reach just the 67% in the peak, for k = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracy_join['k'], accuracy_join['euclidean'], label='euclidean')\n",
    "plt.plot(accuracy_join['k'], accuracy_join['manhattan'], label='manhattan')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_ed = []\n",
    "accuracy_md = []\n",
    "\n",
    "for i in range(200):\n",
    "    accuracy_ed.append(accuracy_total[i][0])\n",
    "    accuracy_md.append(accuracy_total[i][1])\n",
    "\n",
    "max_index = max(enumerate(accuracy_ed), key=lambda x: x[1])[0]\n",
    "print(f\"Euclidean Distance: The value of k with the higher accuracy is {max_index}. Accurasy = {accuracy_ed[max_index]}\")\n",
    "\n",
    "max_index = max(enumerate(accuracy_md), key=lambda x: x[1])[0]\n",
    "print(f\"Manhattan Distance: The value of k with the higher accuracy is: {max_index}. Accurasy = {accuracy_md[max_index]}\")\n",
    "\n",
    "accuracyKNN = accuracy_md[max_index]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Decision Tree</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_drop = X_test.drop(['ra', 'dec', 'u', 'objid','run','rerun','camcol','field','fiberid'], axis = 1) # type: ignore\n",
    "\n",
    "# Create the model\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model\n",
    "clf = clf.fit(X_train_after_balancing, y_train_after_balancing)\n",
    "y_predDT = clf.predict(X_test_drop)\n",
    "\n",
    "# Check the accuracy\n",
    "accuracyDT = accuracy_score(y_test, y_predDT)\n",
    "print(f\"Accuracy: {accuracyDT:.2f}\")\n",
    "\n",
    "# Check the performance\n",
    "scores = cross_val_score(clf, X_train_after_balancing, y_train_after_balancing, cv=5)\n",
    "print(f\"Performances: {scores}\")\n",
    "print(f\"Average performance: {scores.mean():.2f}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_test_drop = X_test.drop(['ra', 'dec', 'u', 'objid','run','rerun','camcol','field','fiberid'], axis = 1) # type: ignore\n",
    "\n",
    "# Create the model\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train_after_balancing, y_train_after_balancing)\n",
    "\n",
    "# Check the accuracy\n",
    "y_predRF = clf.predict(X_test_drop)\n",
    "accuracyRF = accuracy_score(y_test, y_predRF)\n",
    "print(f\"Accuracy: {accuracyRF:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utilizza la cross-validation per valutare l'accuratezza del modello\n",
    "scores = cross_val_score(clf, X_train_after_balancing, y_train_after_balancing, cv=10)\n",
    "\n",
    "# Stampa i risultati della cross-validation\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean score:\", scores.mean())\n",
    "\n",
    "# Disegna la curva di apprendimento del modello\n",
    "train_sizes, train_scores, test_scores = learning_curve(clf, X_train_after_balancing, y_train_after_balancing, cv=10)\n",
    "\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), 'o-', color='r', label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores.mean(axis=1), 'o-', color='g', label=\"Cross-validation score\")\n",
    "\n",
    "plt.title(\"Learning Curves (Random Forest)\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bayesian Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "X_test_drop = X_test.drop(['ra', 'dec', 'u', 'objid','run','rerun','camcol','field','fiberid'], axis = 1) # type: ignore\n",
    "\n",
    "# Create the model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Fit the model\n",
    "gnb.fit(X_train_after_balancing, y_train_after_balancing)\n",
    "\n",
    "# Check the accuracy\n",
    "y_predBC = gnb.predict(X_test_drop)\n",
    "accuracyBC = accuracy_score(y_test, y_predBC)\n",
    "print(f\"Accuracy: {accuracyBC:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ACCURACY</h3>\n",
    "Now we will analize the accuracy of all the tried classifier.<br>\n",
    "We can note that the best algorithm is Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy of Random Forest: {accuracyRF:.2f}\")\n",
    "print(f\"Accuracy of Decision Tree: {accuracyDT:.2f}\")\n",
    "print(f\"Accuracy of KNN: {accuracyKNN:.2f}\")\n",
    "print(f\"Accuracy of Bayesian Classifier: {accuracyBC:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-weight: bold\">Save The Model<h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"size: 12pt\">I'll save the model of Random Forest in a file, for using them in an external application</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('starClassificatinApp/model.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_after_balancing.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Evaluation of the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17408    76   325]\n",
      " [    4  6546     0]\n",
      " [  320     1  5320]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calcola la confusion matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_predRF)\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "108577842efddff3bd4824ec9bdd12effc6dfe96f030cd77b02bee11f8da132d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
